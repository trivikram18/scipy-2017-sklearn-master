{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.570266\n",
      "n_neighbors: 3, average score: 0.656114\n",
      "n_neighbors: 5, average score: 0.774720\n",
      "n_neighbors: 10, average score: 0.716195\n",
      "n_neighbors: 20, average score: 0.603276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.017837\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.086940\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.026153\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.010874\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.006809\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.225298\n",
      "C: 0.010000, gamma: 0.100000, average score: -0.018541\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.087686\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.003652\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.088676\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.528233\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.472122\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.184993\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.577398\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.672894\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.689797\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.588918\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.612310\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.631759\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.712111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.004510202915974926, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=0.00026575657285199394, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.0022361855097154937, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=-0.002649513124963754, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=0.0024770917472168863, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=-0.00012818680073722888, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=0.005717311447114737, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ..... C=0.001, gamma=0.1, score=0.0117261414199058, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=0.009119844189613646, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ...... C=0.001, gamma=1, score=0.00466137792367316, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=0.010532119612328583, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=0.007523987655517651, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=-0.0024658649056223947, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=0.002707888818500148, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=8.600001463854312e-05, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=0.015993712408375438, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=0.023831402327266438, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=0.020936852625056623, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.09262011185601915, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.10920821565410188, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.10559805037089776, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.08121251756720993, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.09559838019566602, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.09299032324134748, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.017799821723697096, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .... C=0.1, gamma=0.001, score=0.02599463385006895, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .... C=0.1, gamma=0.001, score=0.02302713174633586, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.18035856085181556, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.1874984828520767, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.1891426289204985, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ........ C=0.1, gamma=0.1, score=0.506027556490656, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5214651296326696, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5443360471926322, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4839891916020633, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ........ C=0.1, gamma=1, score=0.49785289629566476, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5180087092941382, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.19488706938924782, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.20258072842098296, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.2034035991708797, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5724936378079185, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6105404621392175, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6270153196030374, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ........... C=1, gamma=0.1, score=0.68047005036512, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6426862626019316, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6762865294608439, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7308632443245822, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6629453400077449, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ............ C=1, gamma=1, score=0.729284061060401, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5754491394187246, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6082965071601012, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6229501616806794, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6171588974028794, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6333158570520487, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6613434512850334, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6866053010658237, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6051528964793189, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6724395385252222, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7878761169622367, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.6822051345864268, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ........... C=10, gamma=1, score=0.762977248950859, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7447880663344648\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.deprecation.DeprecationDict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\trivikram.cheedella\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\trivikram.cheedella\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\trivikram.cheedella\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\trivikram.cheedella\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\trivikram.cheedella\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>-0.002184</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.002650</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.008823</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.011726</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.000333         0.000667        -0.002184         -0.000802   0.001   \n",
       "1       0.000333         0.000667        -0.000126          0.001213   0.001   \n",
       "2       0.001000         0.000667         0.008823          0.010034   0.001   \n",
       "3       0.001333         0.000667         0.007543          0.009059   0.001   \n",
       "4       0.000333         0.001000         0.000084          0.001416    0.01   \n",
       "\n",
       "  param_gamma                        params  rank_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}               20   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}               19   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}               16   \n",
       "3           1      {'C': 0.001, 'gamma': 1}               17   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}               18   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0          -0.004510           -0.000049           0.000266   \n",
       "1          -0.002650            0.002006           0.002477   \n",
       "2           0.005717            0.011062           0.011726   \n",
       "3           0.004661            0.010133           0.010532   \n",
       "4          -0.002466            0.002214           0.002708   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0           -0.001390          -0.002236           -0.000968      0.000471   \n",
       "1            0.000651          -0.000128            0.000980      0.000471   \n",
       "2            0.009491           0.009120            0.009549      0.000000   \n",
       "3            0.008744           0.007524            0.008302      0.000471   \n",
       "4            0.000853           0.000086            0.001180      0.000471   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000471        0.001955         0.000560  \n",
       "1        0.000471        0.002098         0.000577  \n",
       "2        0.000471        0.002468         0.000727  \n",
       "3        0.000471        0.002402         0.000780  \n",
       "4        0.000816        0.002117         0.000580  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.666621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.655051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.637072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.744788\n",
       "15       1           1         0.707929\n",
       "14       1         0.1         0.666621\n",
       "18      10         0.1         0.655051\n",
       "17      10        0.01         0.637072"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.22990921130994543, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .... C=0.001, gamma=0.01, score=-0.228421644001781, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=-0.22117000769396178, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.22088565635299862, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ... C=0.01, gamma=0.001, score=-0.2282872996264429, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ..... C=0.01, gamma=0.01, score=-0.213633200294818, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .... C=0.01, gamma=0.1, score=-0.11010689930987372, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=-0.1212047331500199, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=-0.21234541154400444, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] .... C=0.1, gamma=0.01, score=-0.03604363321112203, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.42276863379142293, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.3960043501789632, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ..... C=1, gamma=0.001, score=-0.02302191440303125, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5127891762680417, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6986739118619831, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7584083268197919, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5128192171182604, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.5727500291167283, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.720761930174533, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8639877505510888, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......... n_neighbors=1, score=0.9708029197080292, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ........... n_neighbors=1, score=0.988929889298893, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ........... n_neighbors=1, score=0.988929889298893, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... n_neighbors=1, score=0.9887640449438202, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......... n_neighbors=1, score=0.9886363636363636, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......... n_neighbors=3, score=0.9817518248175182, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ........... n_neighbors=3, score=0.988929889298893, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ........... n_neighbors=3, score=0.985239852398524, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......... n_neighbors=3, score=0.9850187265917603, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......... n_neighbors=3, score=0.9848484848484849, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......... n_neighbors=5, score=0.9854014598540146, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ........... n_neighbors=5, score=0.996309963099631, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ........... n_neighbors=5, score=0.974169741697417, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......... n_neighbors=5, score=0.9850187265917603, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......... n_neighbors=5, score=0.9848484848484849, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......... n_neighbors=10, score=0.9781021897810219, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] .......... n_neighbors=10, score=0.981549815498155, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] .......... n_neighbors=10, score=0.977859778597786, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......... n_neighbors=10, score=0.9812734082397003, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......... n_neighbors=10, score=0.9848484848484849, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] .......... n_neighbors=50, score=0.927007299270073, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.9298892988929889, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.9520295202952029, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.9213483146067416, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......... n_neighbors=50, score=0.9583333333333334, total=   0.0s\n",
      "Score on test set: 0.991111\n",
      "Best parameters: {'n_neighbors': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    5.2s finished\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/14_grid_search.py\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 10, 50]}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Score on test set: %f\" % gs.score(X_test, y_test))\n",
    "print(\"Best parameters: %s\" % gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
